{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xlrd\n",
    "import csv\n",
    "import codecs\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from minepy import MINE\n",
    "from sklearn.feature_selection import VarianceThreshold \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score  \n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xlsx文件类型转换\n",
    "将xlsx文件转换成为csv方便读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xlsx_to_csv(path,doc_name):\n",
    "    workbook = xlrd.open_workbook(path)\n",
    "    table = workbook.sheet_by_index(0)\n",
    "    with codecs.open(doc_name, 'w', encoding='utf-8') as f:\n",
    "        write = csv.writer(f)\n",
    "        for row_num in range(table.nrows):\n",
    "            row_value = table.row_values(row_num)\n",
    "            write.writerow(row_value)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    xlsx_to_csv('1.银行客户流失预警/3.1.train_sample.xlsx','train.csv')\n",
    "    xlsx_to_csv('1.银行客户流失预警/3.2.test_sample.xlsx','test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframe1 = pd.read_csv('train.csv',sep=',')\n",
    "dataframe2 = pd.read_csv('test.csv',sep=',')\n",
    "\n",
    "#讲训练数据与测试数据连接起来，以便一起进行数据清洗\n",
    "merge_data=pd.concat([dataframe1,dataframe2])  \n",
    "merge_data.to_csv('final_data.csv',index=False)    #index=False，写入的时候不写入列的索引序号\n",
    "\n",
    "dataframe = pd.read_csv('final_data.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUST_ID</th>\n",
       "      <th>OPEN_ORG_NUM</th>\n",
       "      <th>IDF_TYP_CD</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>bad_good</th>\n",
       "      <th>LAST_OPEN_TENURE_DAYS</th>\n",
       "      <th>G_OS_PRCP_SUM</th>\n",
       "      <th>OS_PRCP_SUM_THREE</th>\n",
       "      <th>OS_PRCP_SUM_SIX</th>\n",
       "      <th>guozhai_flag</th>\n",
       "      <th>...</th>\n",
       "      <th>L3_CHANNEL_TXN_DTAIN_AVGCNT</th>\n",
       "      <th>L3_CHANNEL_TXN_DOUTTA_AVGCNT</th>\n",
       "      <th>L6_CHANNEL_TXN_STAIN_AVGAMT</th>\n",
       "      <th>L6_CHANNEL_TXN_SOUTTA_AVGAMT</th>\n",
       "      <th>L6_CHANNEL_TXN_DTAIN_AVGAMT</th>\n",
       "      <th>L6_CHANNEL_TXN_DOUTTA_AVGAMT</th>\n",
       "      <th>L6_CHANNEL_TXN_STAIN_AVGCNT</th>\n",
       "      <th>L6_CHANNEL_TXN_SOUTTA_AVGCNT</th>\n",
       "      <th>L6_CHANNEL_TXN_DTAIN_AVGCNT</th>\n",
       "      <th>L6_CHANNEL_TXN_DOUTTA_AVGCNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000000024</td>\n",
       "      <td>1101</td>\n",
       "      <td>ZR01</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>204750.0</td>\n",
       "      <td>197750.00000</td>\n",
       "      <td>98875.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000000515</td>\n",
       "      <td>602</td>\n",
       "      <td>ZR01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000003231</td>\n",
       "      <td>602</td>\n",
       "      <td>ZR01</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>466666.66667</td>\n",
       "      <td>233333.33333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000003736</td>\n",
       "      <td>602</td>\n",
       "      <td>ZR01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000003852</td>\n",
       "      <td>602</td>\n",
       "      <td>ZR01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 627 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CUST_ID  OPEN_ORG_NUM IDF_TYP_CD GENDER  bad_good  \\\n",
       "0  1000000024          1101       ZR01      2       0.0   \n",
       "1  1000000515           602       ZR01      1       0.0   \n",
       "2  1000003231           602       ZR01      2       1.0   \n",
       "3  1000003736           602       ZR01      1       0.0   \n",
       "4  1000003852           602       ZR01      1       0.0   \n",
       "\n",
       "   LAST_OPEN_TENURE_DAYS  G_OS_PRCP_SUM  OS_PRCP_SUM_THREE  OS_PRCP_SUM_SIX  \\\n",
       "0                    0.0       204750.0       197750.00000      98875.00000   \n",
       "1                    0.0            0.0            0.00000          0.00000   \n",
       "2                    6.0            0.0       466666.66667     233333.33333   \n",
       "3                    0.0            0.0            0.00000          0.00000   \n",
       "4                   26.0            0.0            0.00000          0.00000   \n",
       "\n",
       "   guozhai_flag              ...               L3_CHANNEL_TXN_DTAIN_AVGCNT  \\\n",
       "0           0.0              ...                                       0.0   \n",
       "1           0.0              ...                                       0.0   \n",
       "2           0.0              ...                                       0.0   \n",
       "3           0.0              ...                                       0.0   \n",
       "4           0.0              ...                                       0.0   \n",
       "\n",
       "   L3_CHANNEL_TXN_DOUTTA_AVGCNT  L6_CHANNEL_TXN_STAIN_AVGAMT  \\\n",
       "0                           0.0                          0.0   \n",
       "1                           0.0                          0.0   \n",
       "2                           0.0                          0.0   \n",
       "3                           0.0                          0.0   \n",
       "4                           0.0                          0.0   \n",
       "\n",
       "   L6_CHANNEL_TXN_SOUTTA_AVGAMT  L6_CHANNEL_TXN_DTAIN_AVGAMT  \\\n",
       "0                           0.0                          0.0   \n",
       "1                           0.0                          0.0   \n",
       "2                           0.0                          0.0   \n",
       "3                           0.0                          0.0   \n",
       "4                           0.0                          0.0   \n",
       "\n",
       "   L6_CHANNEL_TXN_DOUTTA_AVGAMT  L6_CHANNEL_TXN_STAIN_AVGCNT  \\\n",
       "0                           0.0                          0.0   \n",
       "1                           0.0                          0.0   \n",
       "2                           0.0                          0.0   \n",
       "3                           0.0                          0.0   \n",
       "4                           0.0                          0.0   \n",
       "\n",
       "   L6_CHANNEL_TXN_SOUTTA_AVGCNT  L6_CHANNEL_TXN_DTAIN_AVGCNT  \\\n",
       "0                           0.0                          0.0   \n",
       "1                           0.0                          0.0   \n",
       "2                           0.0                          0.0   \n",
       "3                           0.0                          0.0   \n",
       "4                           0.0                          0.0   \n",
       "\n",
       "   L6_CHANNEL_TXN_DOUTTA_AVGCNT  \n",
       "0                           0.0  \n",
       "1                           0.0  \n",
       "2                           0.0  \n",
       "3                           0.0  \n",
       "4                           0.0  \n",
       "\n",
       "[5 rows x 627 columns]"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"plt.figure(figsize=(16,10))\\nsns.heatmap(dataframe.corr(), square=True,cmap='RdYlGn')\\nplt.show()\""
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''plt.figure(figsize=(16,10))\n",
    "sns.heatmap(dataframe.corr(), square=True,cmap='RdYlGn')\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看缺失值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "列级别的判断，只要该列有为空或者NA的元素，就为True，否则False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in dataframe.isnull().any():\n",
    "    if i == True:\n",
    "        print('There is null value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据格式转换"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "找出需要被处理的列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns_to_treat = []\n",
    "for i in range(len(dataframe.dtypes)):\n",
    "    dtype = dataframe.dtypes[i]\n",
    "    if str(dtype) == 'object':\n",
    "        columns_to_treat.append(i)\n",
    "        \n",
    "dict_objects = dict()\n",
    "for i in columns_to_treat:\n",
    "    column = dataframe.iloc[:,i]\n",
    "    if i not in dict_objects:\n",
    "        dict_objects[i] = []\n",
    "    for j in column : \n",
    "        if j not in dict_objects[i]:\n",
    "            dict_objects[i].append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dict_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 证件类型 IDF_TYP_CD 2: ['ZR01', 'ZR20', 'ZR03', 'ZR09', 'ZR22']\n",
    "for i in range(len(dataframe[dataframe.keys()[2]])):\n",
    "    sym = int(dataframe['IDF_TYP_CD'][i].split('ZR')[1])\n",
    "    dataframe.at[i, 'IDF_TYP_CD'] = sym\n",
    "dataframe['IDF_TYP_CD'] = dataframe['IDF_TYP_CD'].astype(int)\n",
    "\n",
    "# 173,174,175,176\n",
    "# 性别 GENDER 3: ['2', '1', 'X']\n",
    "# 2,1,999\n",
    "for i in range(len(dataframe[dataframe.keys()[3]])):\n",
    "    if dataframe['GENDER'][i] == 'X':\n",
    "        dataframe.at[i,'GENDER'] = 999\n",
    "    else:\n",
    "        dataframe.at[i,'GENDER'] = dataframe['GENDER'][i]\n",
    "dataframe['GENDER'] = dataframe['GENDER'].astype(int)\n",
    "\n",
    "        \n",
    "# C_FUND_FLAG 持有货币型基金标志\n",
    "for m,i,j,k in zip(range(len(dataframe[dataframe.keys()[173]])),range(len(dataframe[dataframe.keys()[174]])),range(len(dataframe[dataframe.keys()[175]])),range(len(dataframe[dataframe.keys()[176]]))):\n",
    "    sym1 = dataframe[dataframe.keys()[174]][i]\n",
    "    sym2 = dataframe[dataframe.keys()[175]][j]\n",
    "    sym3 = dataframe[dataframe.keys()[176]][k]\n",
    "    sym4 = dataframe[dataframe.keys()[173]][m]\n",
    "    if sym4 == 'N':\n",
    "        dataframe.at[m,dataframe.keys()[173]] = 999\n",
    "    if sym4 == '1':\n",
    "        dataframe.at[m,dataframe.keys()[173]] = 1\n",
    "    if sym4 == '0':\n",
    "        dataframe.at[m,dataframe.keys()[173]] = 0\n",
    "        \n",
    "    if sym1 == 'N':\n",
    "        dataframe.at[i,dataframe.keys()[174]] = 999\n",
    "    if sym1 == '1':\n",
    "        dataframe.at[i,dataframe.keys()[174]] = 1\n",
    "    if sym1 == '0':\n",
    "        dataframe.at[i,dataframe.keys()[174]] = 0\n",
    "        \n",
    "    if sym2 == 'N':\n",
    "        dataframe.at[j,dataframe.keys()[175]] = 999\n",
    "    if sym2 == '1':\n",
    "        dataframe.at[j,dataframe.keys()[175]] = 1\n",
    "    if sym2 == '0':\n",
    "        dataframe.at[j,dataframe.keys()[175]] = 0\n",
    "        \n",
    "    if sym3 == 'N':\n",
    "        dataframe.at[k,dataframe.keys()[176]] = 999\n",
    "    if sym3 == '1':\n",
    "        dataframe.at[k,dataframe.keys()[176]] = 1\n",
    "    if sym3 == '0':\n",
    "        dataframe.at[k,dataframe.keys()[176]] = 0\n",
    "dataframe[dataframe.keys()[173]] = dataframe[dataframe.keys()[173]].astype(int)\n",
    "dataframe[dataframe.keys()[174]] = dataframe[dataframe.keys()[173]].astype(int)\n",
    "dataframe[dataframe.keys()[175]] = dataframe[dataframe.keys()[173]].astype(int)\n",
    "dataframe[dataframe.keys()[176]] = dataframe[dataframe.keys()[173]].astype(int)\n",
    "\n",
    "\n",
    "# 所有只关于Y和N的列      \n",
    "lst = []\n",
    "for i in dict_objects:\n",
    "    for j in dict_objects[i]:\n",
    "        if j != 'N' and j != 'Y':\n",
    "            break\n",
    "        else:\n",
    "            lst.append(i)\n",
    "for i in lst:\n",
    "    for j in range(len(dataframe)):\n",
    "        if dataframe.iloc[j,i] == 'N':\n",
    "            dataframe.at[j,dataframe.keys()[i]] = 0\n",
    "        else:\n",
    "            dataframe.at[j,dataframe.keys()[i]] = 1\n",
    "    dataframe[dataframe.keys()[i]] = dataframe[dataframe.keys()[i]].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Columns: 627 entries, CUST_ID to L6_CHANNEL_TXN_DOUTTA_AVGCNT\n",
      "dtypes: float64(593), int64(34)\n",
      "memory usage: 9.6 MB\n"
     ]
    }
   ],
   "source": [
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征选择"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>特征是否发散：</strong>如果一个特征不发散，例如方差接近于0，也就是说样本在这个特征上基本上没有差异，这个特征对于样本的区分并没有什么用。此处用的是标准差。<br>\n",
    "去除标准差为0的列：该列中只有一个值，因此对预测无用<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = dataframe[dataframe.columns.difference(['bad_good'])]\n",
    "y = dataframe['bad_good']\n",
    "sel = VarianceThreshold(threshold=(.9 * (1 - .9))) \n",
    "new_X = sel.fit_transform(X,y)\n",
    "\n",
    "# 找出需要删除的变量名\n",
    "to_drop = []\n",
    "for i in range(len(sel.get_support())):\n",
    "    if sel.get_support()[i] == False:\n",
    "        to_drop.append(X.keys()[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "删除要删除的变量名字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframe = dataframe.drop(to_drop,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 卡方检验"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看有无负数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'columns_with_negatives = []\\nfor i in dataframe.keys():\\n    lst = list(dataframe[i])\\n    for j in lst:\\n        if j < 0:\\n            columns_with_negatives.append(i)\\n            break\\ncolumns_with_negatives'"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''columns_with_negatives = []\n",
    "for i in dataframe.keys():\n",
    "    lst = list(dataframe[i])\n",
    "    for j in lst:\n",
    "        if j < 0:\n",
    "            columns_with_negatives.append(i)\n",
    "            break\n",
    "columns_with_negatives'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对包含负值的列建立新的列，若为负值，则对应位置为1，原来的负值取绝对值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for i in columns_with_negatives:\\n    dataframe[str(i)+'_SYMBOL'] = 0\\n    \\nfor i in columns_with_negatives:\\n    for j in range(len(dataframe[i])):\\n        if dataframe[i][j] < 0:\\n            dataframe[str(i)+'_SYMBOL'] = 1\\n            dataframe.at[j,i] = abs(dataframe[i][j])\""
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for i in columns_with_negatives:\n",
    "    dataframe[str(i)+'_SYMBOL'] = 0\n",
    "    \n",
    "for i in columns_with_negatives:\n",
    "    for j in range(len(dataframe[i])):\n",
    "        if dataframe[i][j] < 0:\n",
    "            dataframe[str(i)+'_SYMBOL'] = 1\n",
    "            dataframe.at[j,i] = abs(dataframe[i][j])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from sklearn.feature_selection import SelectKBest\\nfrom sklearn.feature_selection import chi2\\n\\nX = dataframe[dataframe.columns.difference(['bad_good'])]\\ny = dataframe['bad_good']\\nX = SelectKBest(chi2, k=int(len(dataframe.keys())*0.9)).fit_transform(X, y)\""
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "X = dataframe[dataframe.columns.difference(['bad_good'])]\n",
    "y = dataframe['bad_good']\n",
    "X = SelectKBest(chi2, k=int(len(dataframe.keys())*0.9)).fit_transform(X, y)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 互信息数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = dataframe[dataframe.columns.difference(['bad_good'])]\n",
    "y = dataframe['bad_good']\n",
    "\n",
    "to_drop = []\n",
    "m = MINE()\n",
    "for i in X.keys():\n",
    "    m.compute_score(X[i], y)\n",
    "    if (m.mic()) < 0.005:\n",
    "        to_drop.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X.drop(to_drop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 343)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "树算法计算特征的信息量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier \n",
    "clf = ExtraTreesClassifier() \n",
    "clf.fit(X,y)\n",
    "\n",
    "# 各个特征重要性 \n",
    "#print(clf.feature_importances_)\n",
    "to_drop = []\n",
    "for i in range(len(clf.feature_importances_)):\n",
    "    if clf.feature_importances_[i] == 0.0:\n",
    "        to_drop.append(X.keys()[i])\n",
    "X = X.drop(to_drop,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN，决策树，naive bayes，逻辑回归，SVM，adaboost <br>\n",
    "https://blog.csdn.net/wu18663419760/article/details/70140009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression : 0.9099958093488084\n",
      "naive_bayes : 0.4118339864624154\n",
      "KNeighborsClassifier : 0.9164970812317577\n",
      "DecisionTreeClassifier : 0.8659955905974412\n",
      "SVC : 0.9235021187632423\n",
      "RandomForestClassifier : 0.9145083219270121\n"
     ]
    }
   ],
   "source": [
    "clf1 = LogisticRegression()  \n",
    "clf2 = GaussianNB()\n",
    "clf3 = KNeighborsClassifier()\n",
    "clf4 = DecisionTreeClassifier()\n",
    "clf5 = SVC()\n",
    "clf6 = RandomForestClassifier()\n",
    "\n",
    "# X:features  y:targets  cv:k  \n",
    "print(str(\"LogisticRegression : \") + str(np.mean(cross_val_score(clf1, X, y, cv=5))))\n",
    "print(str(\"naive_bayes : \") + str(np.mean(cross_val_score(clf2, X, y, cv=5))))\n",
    "print(str(\"KNeighborsClassifier : \") + str(np.mean(cross_val_score(clf3, X, y, cv=5))))\n",
    "print(str(\"DecisionTreeClassifier : \") + str(np.mean(cross_val_score(clf4, X, y, cv=5))))\n",
    "print(str(\"SVC : \") + str(np.mean(cross_val_score(clf5, X, y, cv=5))))\n",
    "print(str(\"RandomForestClassifier : \") + str(np.mean(cross_val_score(clf6, X, y, cv=5))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "淘汰naive_bayes和DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AUC值为ROC曲线所覆盖的区域面积，显然，AUC越大，分类器分类效果越好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''from sklearn.cross_validation import cross_val_score, ShuffleSplit\n",
    "names = dataframe.keys()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''rf = LogisticRegression()\n",
    "scores = []\n",
    "for i in range(X.shape[1]):\n",
    "    score = cross_val_score(rf, X.iloc[:, i:i+1], y, scoring=\"roc_auc\",cv=ShuffleSplit(len(X), 3, .3))\n",
    "    scores.append((round(np.mean(score), 3), names[i]))\n",
    "res_LogisticRegression = sorted(scores, reverse=True)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''rf = KNeighborsClassifier()\n",
    "scores = []\n",
    "for i in range(X.shape[1]):\n",
    "    score = cross_val_score(rf, X.iloc[:, i:i+1], y, scoring=\"roc_auc\",cv=ShuffleSplit(len(X), 3, .3))\n",
    "    scores.append((round(np.mean(score), 3), names[i]))\n",
    "res_KNeighborsClassifier = sorted(scores, reverse=True)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''rf = DecisionTreeClassifier()\n",
    "scores = []\n",
    "for i in range(X.shape[1]):\n",
    "    score = cross_val_score(rf, X.iloc[:, i:i+1], y, scoring=\"roc_auc\",cv=ShuffleSplit(len(X), 3, .3))\n",
    "    scores.append((round(np.mean(score), 3), names[i]))\n",
    "res_DecisionTreeClassifier = sorted(scores, reverse=True)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''rf = SVC()\n",
    "scores = []\n",
    "for i in range(X.shape[1]):\n",
    "    score = cross_val_score(rf, X.iloc[:, i:i+1], y, scoring=\"roc_auc\",cv=ShuffleSplit(len(X), 3, .3))\n",
    "    scores.append((round(np.mean(score), 3), names[i]))\n",
    "res_SVC = sorted(scores, reverse=True)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''rf = RandomForestClassifier()\n",
    "scores = []\n",
    "for i in range(X.shape[1]):\n",
    "    score = cross_val_score(rf, X.iloc[:, i:i+1], y, scoring=\"roc_auc\",cv=ShuffleSplit(len(X), 3, .3))\n",
    "    scores.append((round(np.mean(score), 3), names[i]))\n",
    "res_RandomForestClassifier = sorted(scores, reverse=True)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''length = int(len(res_LogisticRegression) * 0.9)\n",
    "\n",
    "low_LogisticRegression = [res_LogisticRegression[i] for i in range(length,len(res_LogisticRegression))]\n",
    "low_KNeighborsClassifier = [res_KNeighborsClassifier[i] for i in range(length,len(res_KNeighborsClassifier))]\n",
    "low_DecisionTreeClassifier = [res_DecisionTreeClassifier[i] for i in range(length,len(res_DecisionTreeClassifier))]\n",
    "low_SVC = [res_SVC[i] for i in range(length,len(res_SVC))]\n",
    "low_RandomForestClassifier = [res_RandomForestClassifier[i] for i in range(length,len(res_RandomForestClassifier))]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据分割"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "重新拆分为训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframe_train = dataframe.loc[0:999]\n",
    "dataframe_test = dataframe.loc[1000::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X[0:999]\n",
    "y_train = y[0:999]\n",
    "X_test = X[1000::]\n",
    "y_test = y[1000::]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据不均衡处理\n",
    "https://www.cnblogs.com/xyou/p/9075443.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpt1 = 0\n",
    "for i in dataframe['bad_good']:\n",
    "    if i == 1.0:\n",
    "        cpt1+=1\n",
    "cpt1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>conclusion :</strong> target为1的行仅有153行，总行数为999行，数据明显不均衡，需要进行采样处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    0.914915\n",
      "1.0    0.085085\n",
      "Name: bad_good, dtype: float64\n",
      "1.0    0.5\n",
      "0.0    0.5\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 对训练数据集作平衡处理\n",
    "over_samples = SMOTE(random_state=1234) \n",
    "over_samples_X,over_samples_y = over_samples.fit_sample(X_train, y_train)\n",
    "\n",
    "# 重抽样前的类别比例\n",
    "print(y_train.value_counts()/len(y_train))\n",
    "# 重抽样后的类别比例\n",
    "print(pd.Series(over_samples_y).value_counts()/len(over_samples_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_X_train = pd.DataFrame(over_samples_X)\n",
    "new_y_train = pd.DataFrame(over_samples_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "修改列名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_X_train.columns = X.keys()\n",
    "new_y_train.columns = y.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "过采样前"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      1.00      0.96       932\n",
      "        1.0       0.00      0.00      0.00        68\n",
      "\n",
      "avg / total       0.87      0.93      0.90      1000\n",
      "\n",
      "[[932   0]\n",
      " [ 68   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "clf1 = SVC()\n",
    "clf1.fit(X_train, y_train)\n",
    "y_predict = clf1.predict(X_test)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(y_test, y_predict))\n",
    "print(metrics.confusion_matrix(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      1.00      0.96       932\n",
      "        1.0       0.00      0.00      0.00        68\n",
      "\n",
      "avg / total       0.87      0.93      0.90      1000\n",
      "\n",
      "[[932   0]\n",
      " [ 68   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "clf1 = SVC()\n",
    "clf1.fit(new_X_train, new_y_train)\n",
    "y_predict = clf1.predict(X_test)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(y_test, y_predict))\n",
    "print(metrics.confusion_matrix(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RBF 分类模型\n",
    "# C 惩罚参数C 默认值是1.0 \n",
    "    # C越大，相当于惩罚松弛变量，希望松弛变量接近0，即对误分类的惩罚增大，趋向于对训练集全分对的情况，这样对训练集测试时准确率很高，\n",
    "    # 但泛化能力弱。C值小，对误分类的惩罚减小，允许容错，将他们当成噪声点，泛化能力较强。\n",
    "# gamma ： ‘rbf’,‘poly’ 和‘sigmoid’的核函数参数。默认是’auto’，则会选择1/n_features\n",
    "clf1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调参后 <br>\n",
    "https://blog.csdn.net/szlcw1/article/details/52336824"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "无过采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.05, 'gamma': 1}\n",
      "0.914914914914915\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_train_new = StandardScaler().fit_transform(X_train)\n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid={\"C\":[0.05, 0.1, 0.5, 1, 3, 5], \"gamma\": [1, 0.1, 0.01]}, cv=3)\n",
    "grid.fit(X_train_new, y_train)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      1.00      0.96       932\n",
      "        1.0       0.00      0.00      0.00        68\n",
      "\n",
      "avg / total       0.87      0.93      0.90      1000\n",
      "\n",
      "[[932   0]\n",
      " [ 68   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "clf1 = SVC(C=0.05,gamma=1)\n",
    "clf1.fit(X_train, y_train)\n",
    "y_predict = clf1.predict(X_test)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(y_test, y_predict))\n",
    "print(metrics.confusion_matrix(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有过采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import numpy as np\\nfrom sklearn.grid_search import GridSearchCV\\nfrom sklearn.preprocessing import StandardScaler\\nX_train_new = StandardScaler().fit_transform(new_X_train)\\n\\ngrid = GridSearchCV(SVC(), param_grid={\"C\":[0.05, 0.1, 0.5, 1, 3, 5], \"gamma\": [1, 0.1, 0.01]}, cv=3)\\ngrid.fit(new_X_train, new_y_train)\\nprint(grid.best_params_)\\nprint(grid.best_score_)'"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import numpy as np\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_train_new = StandardScaler().fit_transform(new_X_train)\n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid={\"C\":[0.05, 0.1, 0.5, 1, 3, 5], \"gamma\": [1, 0.1, 0.01]}, cv=3)\n",
    "grid.fit(new_X_train, new_y_train)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "无过采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      0.98      0.96       932\n",
      "        1.0       0.17      0.06      0.09        68\n",
      "\n",
      "avg / total       0.88      0.92      0.90      1000\n",
      "\n",
      "[[913  19]\n",
      " [ 64   4]]\n"
     ]
    }
   ],
   "source": [
    "clf2 = LogisticRegression()\n",
    "clf2.fit(X_train, y_train)\n",
    "y_predict = clf2.predict(X_test)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(y_test, y_predict))\n",
    "print(metrics.confusion_matrix(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有过采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.58      0.72       932\n",
      "        1.0       0.09      0.56      0.15        68\n",
      "\n",
      "avg / total       0.89      0.58      0.68      1000\n",
      "\n",
      "[[542 390]\n",
      " [ 30  38]]\n"
     ]
    }
   ],
   "source": [
    "clf2 = LogisticRegression()\n",
    "clf2.fit(new_X_train, new_y_train)\n",
    "y_predict = clf2.predict(X_test)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(y_test, y_predict))\n",
    "print(metrics.confusion_matrix(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调参后<br>\n",
    "https://blog.csdn.net/code_caq/article/details/72027012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.05, 'solver': 'lbfgs'}\n",
      "0.8908908908908909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "new_X_train = StandardScaler().fit_transform(X_train)\n",
    "\n",
    "grid = GridSearchCV(clf2, param_grid={\"C\":[0.05, 0.1, 0.5, 1, 3, 5], \"solver\": ['liblinear', 'lbfgs', 'newton-cg','sag']}, cv=3)\n",
    "grid.fit(new_X_train, y_train)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      0.99      0.96       932\n",
      "        1.0       0.00      0.00      0.00        68\n",
      "\n",
      "avg / total       0.87      0.92      0.89      1000\n",
      "\n",
      "[[921  11]\n",
      " [ 68   0]]\n"
     ]
    }
   ],
   "source": [
    "clf2 = LogisticRegression(C=0.05,solver='lbfgs')\n",
    "clf2.fit(X_train, y_train)\n",
    "y_predict = clf2.predict(X_test)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(y_test, y_predict))\n",
    "print(metrics.confusion_matrix(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "无过采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      0.99      0.96       932\n",
      "        1.0       0.24      0.06      0.09        68\n",
      "\n",
      "avg / total       0.89      0.92      0.90      1000\n",
      "\n",
      "[[919  13]\n",
      " [ 64   4]]\n"
     ]
    }
   ],
   "source": [
    "clf3 = KNeighborsClassifier()\n",
    "clf3.fit(X_train, y_train)\n",
    "y_predict = clf3.predict(X_test)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(y_test, y_predict))\n",
    "print(metrics.confusion_matrix(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有过采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.78      0.85       932\n",
      "        1.0       0.12      0.41      0.18        68\n",
      "\n",
      "avg / total       0.89      0.75      0.81      1000\n",
      "\n",
      "[[724 208]\n",
      " [ 40  28]]\n"
     ]
    }
   ],
   "source": [
    "clf3 = KNeighborsClassifier()\n",
    "clf3.fit(new_X_train, new_y_train)\n",
    "y_predict = clf3.predict(X_test)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(y_test, y_predict))\n",
    "print(metrics.confusion_matrix(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调参后<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'leaf_size': 20, 'n_jobs': 1, 'n_neighbors': 9}\n",
      "0.8388388388388388\n"
     ]
    }
   ],
   "source": [
    "new_X_train = StandardScaler().fit_transform(X_train)\n",
    "\n",
    "grid = GridSearchCV(clf3, param_grid={\"n_neighbors\":[3,5,7,9], \n",
    "                                      \"leaf_size\": [20,25,30,35,40],\n",
    "                                     \"n_jobs\":[1,2,3]}, \n",
    "                    cv=3)\n",
    "grid.fit(new_X_train, y_train)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      0.99      0.96       932\n",
      "        1.0       0.33      0.06      0.10        68\n",
      "\n",
      "avg / total       0.89      0.93      0.90      1000\n",
      "\n",
      "[[924   8]\n",
      " [ 64   4]]\n"
     ]
    }
   ],
   "source": [
    "clf3 = KNeighborsClassifier(leaf_size=20,n_neighbors=9)\n",
    "clf3.fit(X_train, y_train)\n",
    "y_predict = clf3.predict(X_test)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(y_test, y_predict))\n",
    "print(metrics.confusion_matrix(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "无过采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      0.91      0.92       932\n",
      "        1.0       0.12      0.18      0.15        68\n",
      "\n",
      "avg / total       0.88      0.86      0.87      1000\n",
      "\n",
      "[[847  85]\n",
      " [ 56  12]]\n"
     ]
    }
   ],
   "source": [
    "clf4 = DecisionTreeClassifier()\n",
    "clf4.fit(X_train, y_train)\n",
    "y_predict = clf4.predict(X_test)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(y_test, y_predict))\n",
    "print(metrics.confusion_matrix(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有过采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      0.90      0.92       932\n",
      "        1.0       0.14      0.22      0.17        68\n",
      "\n",
      "avg / total       0.89      0.85      0.87      1000\n",
      "\n",
      "[[840  92]\n",
      " [ 53  15]]\n"
     ]
    }
   ],
   "source": [
    "clf4 = DecisionTreeClassifier()\n",
    "clf4.fit(new_X_train, new_y_train)\n",
    "y_predict = clf4.predict(X_test)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(y_test, y_predict))\n",
    "print(metrics.confusion_matrix(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调参后<br>\n",
    "https://blog.csdn.net/akon_wang_hkbu/article/details/77621631"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 10, 'max_features': 200}\n",
      "0.7647647647647647\n"
     ]
    }
   ],
   "source": [
    "new_X_train = StandardScaler().fit_transform(X_train)\n",
    "\n",
    "grid = GridSearchCV(clf4, param_grid={\"max_features\":[80,100,150,200,250], \n",
    "                                      \"max_depth\": [5,10,20,30,40],\n",
    "                                     }, \n",
    "                    cv=3)\n",
    "grid.fit(new_X_train, y_train)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      0.99      0.96       932\n",
      "        1.0       0.33      0.06      0.10        68\n",
      "\n",
      "avg / total       0.89      0.93      0.90      1000\n",
      "\n",
      "[[924   8]\n",
      " [ 64   4]]\n"
     ]
    }
   ],
   "source": [
    "clf4 = DecisionTreeClassifier(max_depth=10,max_features=200)\n",
    "clf4.fit(X_train, y_train)\n",
    "y_predict = clf3.predict(X_test)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(y_test, y_predict))\n",
    "print(metrics.confusion_matrix(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "无过采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      1.00      0.96       932\n",
      "        1.0       0.50      0.06      0.11        68\n",
      "\n",
      "avg / total       0.91      0.93      0.91      1000\n",
      "\n",
      "[[928   4]\n",
      " [ 64   4]]\n"
     ]
    }
   ],
   "source": [
    "clf5 = RandomForestClassifier()\n",
    "clf5.fit(X_train, y_train)\n",
    "y_predict = clf5.predict(X_test)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(y_test, y_predict))\n",
    "print(metrics.confusion_matrix(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有过采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.93      0.94       932\n",
      "        1.0       0.23      0.26      0.24        68\n",
      "\n",
      "avg / total       0.90      0.89      0.89      1000\n",
      "\n",
      "[[871  61]\n",
      " [ 50  18]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "clf5 = RandomForestClassifier()\n",
    "clf5.fit(new_X_train, new_y_train)\n",
    "y_predict = clf5.predict(X_test)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(y_test, y_predict))\n",
    "print(metrics.confusion_matrix(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调参后<br>\n",
    "https://blog.csdn.net/yanyanyufei96/article/details/71213351"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 2, 'min_samples_split': 2, 'n_estimators': 55}\n",
      "0.914914914914915\n"
     ]
    }
   ],
   "source": [
    "new_X_train = StandardScaler().fit_transform(X_train)\n",
    "\n",
    "grid = GridSearchCV(clf5, param_grid={'n_estimators': [10,25,40,55,60],\n",
    "                                     'max_depth': [2,3,4,5], \n",
    "                                     'min_samples_split':[2,4,6,8,10]\n",
    "                                     },\n",
    "                    cv=3)\n",
    "grid.fit(new_X_train, y_train)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      0.99      0.96       932\n",
      "        1.0       0.30      0.04      0.08        68\n",
      "\n",
      "avg / total       0.89      0.93      0.90      1000\n",
      "\n",
      "[[925   7]\n",
      " [ 65   3]]\n"
     ]
    }
   ],
   "source": [
    "clf5 = RandomForestClassifier(n_estimators = 2, max_depth = 2, min_samples_split = 55)\n",
    "clf5.fit(X_train, y_train)\n",
    "y_predict = clf5.predict(X_test)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(y_test, y_predict))\n",
    "print(metrics.confusion_matrix(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "无过采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "clf6 =  xgboost.XGBClassifier( \n",
    "         learning_rate =0.05,\n",
    "         n_estimators=200,\n",
    "         max_depth=5,\n",
    "         min_child_weight=1,\n",
    "         gamma=0.1,\n",
    "         subsample=0.8,\n",
    "         colsample_bytree=0.8,\n",
    "         objective= 'binary:logistic',\n",
    "         nthread=4,\n",
    "         scale_pos_weight=1,\n",
    "         seed=27)\n",
    "clf6.fit(X_train,y_train)\n",
    "res = clf6.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      0.99      0.96       932\n",
      "        1.0       0.30      0.04      0.08        68\n",
      "\n",
      "avg / total       0.89      0.93      0.90      1000\n",
      "\n",
      "[[925   7]\n",
      " [ 65   3]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_predict))\n",
    "print(metrics.confusion_matrix(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有过采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "clf6 =  xgboost.XGBClassifier( \n",
    "         learning_rate =0.05,\n",
    "         n_estimators=200,\n",
    "         max_depth=5,\n",
    "         min_child_weight=1,\n",
    "         gamma=0.1,\n",
    "         subsample=0.8,\n",
    "         colsample_bytree=0.8,\n",
    "         objective= 'binary:logistic',\n",
    "         nthread=4,\n",
    "         scale_pos_weight=1,\n",
    "         seed=27)\n",
    "clf6.fit(new_X_train,new_y_train)\n",
    "res = clf6.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.93      0.94       932\n",
      "        1.0       0.23      0.26      0.24        68\n",
      "\n",
      "avg / total       0.90      0.89      0.89      1000\n",
      "\n",
      "[[871  61]\n",
      " [ 50  18]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_predict))\n",
    "print(metrics.confusion_matrix(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0.1, learning_rate=0.05,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=1, missing=None,\n",
       "       n_estimators=200, n_jobs=1, nthread=4, objective='binary:logistic',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=27, silent=True, subsample=0.8)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调参后<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(clf6, param_grid={'learning_rate': [0.03,0.05,0.1,0.15,0.2],\n",
    "                                     'n_estimators': [100,200,300,400,500]\n",
    "                                     },\n",
    "                    cv=3)\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "clf6 =  xgboost.XGBClassifier( \n",
    "         learning_rate =0.15,\n",
    "         n_estimators=400,\n",
    "         max_depth=5,\n",
    "         min_child_weight=1,\n",
    "         gamma=0.1,\n",
    "         subsample=0.8,\n",
    "         colsample_bytree=0.8,\n",
    "         objective= 'binary:logistic',\n",
    "         nthread=4,\n",
    "         scale_pos_weight=1,\n",
    "         seed=27)\n",
    "clf6.fit(X_train,y_train)\n",
    "res = clf6.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.93      0.99      0.96       932\n",
      "        1.0       0.30      0.04      0.08        68\n",
      "\n",
      "avg / total       0.89      0.93      0.90      1000\n",
      "\n",
      "[[925   7]\n",
      " [ 65   3]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_predict))\n",
    "print(metrics.confusion_matrix(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
